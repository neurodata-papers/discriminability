\documentclass{article}
\input{preamble.tex}

\title{\vspace{-50pt}
% Reliable and Reproducible Brain-Based Measures for Candidate Biomarker Discovery from Big Data
% Optimal Discovery Science from Big Brain-Imaging Data via Reliability and Reproducibility  
\db{Optimal Design for Discovery Science via Maximizing Discriminability: \\ Applications in Neuroimaging}
}
\author{Shangsi Wang, Zhi Yang, Xi-Nian Zuo, Michael Milham, Cameron Craddock,  \\ 
Greg Kiar, William Gray Roncal, Eric Bridgeford,
Consortium for Reliability and Reproducibility, \\ Carey E.~Priebe, Joshua T. Vogelstein}


\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction}

\para{Opportunity and Challenge} In this era of big data, many scientific, government, and corporate groups are collecting and processing massive datasets. To obtain optimal quantitative answers to any inquiry about data requires making two decisions: (i) “how should the data be collected?”, and (ii) “how should the data be processed?”  When the downstream inference task is specified, a priori, we can collect and process data to optimize the performance of task. However, recently, across industry, governmental, and academic settings, certain datasets become benchmark or reference datasets. Such datasets can then be used for a wide variety of different inferential problems.  Collecting and processing these datasets requires massive institutional investments, and choices related to questions(i) and (ii) above have dramatic effects on all subsequent analyses. Optimally addressing experimental design decisions can yield significant savings in both the financial and human costs, and also improve accuracy of analytical results. Therefore, a theoretical framework to enable investigators to select from a set of possible design decisions using pilot data could reap great rewards



\para{Action and Resolution} 
To this end, we have proposed and developed a formal definition of discriminability to guide data collection and processing. Discriminability is a non-parametric statistical property of a joint distribution in a hierarchical model, to differentiate between classes of objects. We prove that discriminability (which may be more aptly called reliability), provides a lower bound on predictive accuracy for any downstream inference task, even if we have never seen the covariates to predict. We then design an estimator of discriminability computed from test-restest data set, demonstrate that it is unbiased, and derive our estimator’s asymptotic distribution. 

Numerical simulations are conducted to demonstrate the basic property of our discriminability estimator in a variety of settings. Then, we apply our approach to choose amongst a set of choices one must make when designing a neuroimaging study to specifically study functional connectomics. We start by finding the maximally reliable threshold for converting correlation matrices  into graphs. Indeed, consistent with our theoretical and simulated results,
maximizing the discriminability of our datasets also maximizes performance on a suite of different downstream inference tasks. We then ask about a series of pre-processing steps: should one motion correct or not, and
should one implement global signal regression or not, etc. We determine the optimal choice for each pre-processing steps, and find the maximally discriminable pipelines amongst 64 pre-processing pipelines.

Thus, in total, our reliability analysis is a powerful tool for making decisions about how to collect and analyze
datasets designed for discovery science. We expect this method to be useful in a wide variety of applications,
and therefore have made all the code open source and available from http://openconnecto.
me.




\section{Results}



\subsection{Theory}

\subsubsection{Definition of Discriminability}
 Discriminability measures the overall consistency and differentiability of observations. For example, if a subject is measured twice under the same conditions, two observations should be close to each other given the measure is consistent. In addition, one should be able to tell these two observations come from the same subject when compared to observations from other subjects given the measure is differentiable. We quantify this idea of consistency and differentiability through discriminability. 
 
To formalize the definition of discriminability, consider the following generative process. For each sample $i$, there exists some true physical property $\bv_i$. Unfortunately, we do not get to directly observed $\bv_i$, rather, we measure it with some device, that transforms the truth from $\bv_i$ to $\bw_i$ via $f_{\bphi}$.  The parameter $\bphi \in \bPhi$ characterizes all options in the measurement, including, for example, which scanner to use, which resolution, the number of images, sampling rate, etc.  The output of $f_{\bphi}$ is the  ``raw'' observation data $\bw_i$, but it is corrupt in various ways, including movement or intensity artifacts introduced by the measurement process.  Therefore, rather than operating directly on $\bw_i$, we intentionally ``pre-process'' the data, in an effort to remove a number of nuisance variables.  This pre-processing procedure further transforms the data from $\bw_i$ to $\bx_i$ via $g_{\bpsi}$.   The parameter $\bpsi \in \bPsi$ indexes all pre-processing options, including whether to perform motion correction, which motion correction, deconvolution, etc.  More specifically, the entire code base, including dependencies, and even the hardware the pre-processing is running on, could count as $\bpsi$. For brevity, we define $\bx_i:= g_{\bpsi} \big(f_{\bphi} (\bv_i) \big)$.

Let $i$ denote the sample's unique \emph{identity} (hereafter, referred to as the \emph{subject}) and $t$ denote the trial number.  Thus, there is a single $\bv_i$ for subject $i$, but we have $\bw_{i,t}$, which is the $t^{th}$ trial, implicitly also a function of $\bphi$, which encodes all the details of the measurement. If both $f$ and $g$ together do not introduce too much noise, then we would expect that $\bx_{i,1}$ and $\bx_{i,2}$ are \emph{closer} to one another than either are to any other subject's data, $\bx_{i',t}$.  Define $\delta$ to be a metric computing the distance between two data points, $\delta \from \mc{X} \times \mc{X} \to \Real_+$.  Formally, we expect that $\delta(\bx_{i,t},\bx_{i,t'}) \leq \delta(\bx_{i,t},\bx_{i',t''})$, for any $i,i',t,t',t''$.  
For brevity, let $\delta_{i,t,t'}:=\delta(\bx_{i,t}, \bx_{i,t'})$ and 
$\delta_{i,i',t,t'}:=\delta(\bx_{i,t}, \bx_{i',t''})$.  
This intuition leads to our definition of discriminability:
\begin{align}
D(\bpsi,\bphi) = \PP[ \delta_{i,t,t'} \leq \delta_{i,i',t,t'}]
\end{align}
When tring to find the best pre-processing routine encoded by $\bpsi$, we try to maximize the discriminability of processed data, that is 
\begin{equation} 
\begin{aligned}
& \underset{\bpsi \in \bPsi}{\text{maximize}}
& & D(\bpsi,\bphi)
\end{aligned}
\end{equation}


\subsubsection{Optimizing discriminability Optimizes Bound on Performance for Any Task}
In addition to $\bv_i$, there are other properties of sample $i$ of interest; we call all of them $\by_i \in \mc{Y}$.  These may include, for example, the phenotype of the subject, including personality tests, demographic information, and genetic data.  The goal of experimental design, in this context, is to choose $\bphi \in \bPhi$ and $\bpsi \in \bPsi$ to maximize some function of  $(\bx_i, \by_i)$.  



To quantify the performance of our choice, we introduce some assumptions.  First, assume that each $(\bV_i,\bY_i)$ pair is sampled independently and identically from some distribution, $(\bV_i,\bY_i) \iid F_{V,Y}$.  For simplicity, let us assume that our goal is regression, using $\bX_i$ as the \emph{predictor} variables, and a single dimension of $\bY_i$ as the \emph{target} variable (we will generalize these assumptions below).  Moreover, let $h \from \mc{X} \to \mc{Y}$ be the regression function (which we will typically learn from the data).  The loss function, $\ell$ quantifies the error of our predictions, $\ell( h(\bx_i), \by_i) \in \Real_+$.  

\subsubsection{Estimator/Test Statistic}

\begin{itemize}
\item an estimator of D, called Dhat

\item proof that our estimator is unbiased (in a model free setting), 
$E(Dhat)=D$.

\item proof that our estimator asymptotically converges to truth (in a model free setting), $\mh{D}_n \conv D$
\end{itemize}


\subsection{Simulations}

\subsubsection{Dhat $\conv$ E(D) in practice for some (eg, gaussian) simulation}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/simumnr_violin.png}
\caption{}
\label{fig:64}
\end{figure}




\subsubsection{Dhat provides a more useful bound than ICC or I2C2 for a variety of simulated settings}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/Figure1_draft.png}
\caption{}
\label{fig:64}
\end{figure}



\subsubsection{we can use Dhat to choose the most discriminable parameter (eg, threshold)}


\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/parameter_selection_2sub.png}
\caption{}
\label{fig:64}
\end{figure}




\subsection{Connectome Applications}

\subsubsection{optimal Discriminability yields optimal predictive accuracy}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/HCP.png}
\caption{}
\label{fig:64}
\end{figure}


\subsubsection{Best Pipeline of 64}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/64_pipelines_gg.png}
\caption{}
\label{fig:64}
\end{figure}


\subsubsection{best pipeline = product of marginals}


\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/Differ_violin_mean.png}
\caption{}
\label{fig:64}
\end{figure}



\subsubsection{thresholding vs. binning ranks}

\subsubsection{which atlas/resolution}


\subsubsection{DTI vs. fMRI}










\section{Discussion}

\para{Summary}

\para{Related Work}


\para{Next Steps}


% \input{intro}
% \input{simulations}
% \input{flow}
% \input{setting}
% \input{logic}
% \input{main}
% \input{setup}
% \input{gRAICAR}



\appendix






\newpage
\small{
\bibliography{biblio}
\bibliographystyle{IEEEtran}
}


\end{document}
