\documentclass{article}
\input{preamble.tex}

\title{\vspace{-50pt}
% Reliable and Reproducible Brain-Based Measures for Candidate Biomarker Discovery from Big Data
% Optimal Discovery Science from Big Brain-Imaging Data via Reliability and Reproducibility  
\db{Optimal Design for Discovery Science via Maximizing Discriminability: \\ Applications in Neuroimaging}
}
\author{Shangsi Wang, Zhi Yang, Xi-Nian Zuo, Michael Milham, Cameron Craddock,  \\ 
Greg Kiar, William Gray Roncal, Eric Bridgeford,
Consortium for Reliability and Reproducibility, \\ Carey E.~Priebe, Joshua T. Vogelstein}


\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction}

\para{Opportunity and Challenge} In this era of big data, many scientific, government, and corporate groups are collecting and processing massive datasets. To obtain optimal quantitative answers to any inquiry about data requires making two decisions: (i) “how should the data be collected?”, and (ii) “how should the data be processed?”  When the downstream inference task is specified, a priori, we can collect and process data to optimize the performance of task. However, recently, across industry, governmental, and academic settings, certain datasets become benchmark or reference datasets. Such datasets can then be used for a wide variety of different inferential problems.  Collecting and processing these datasets requires massive institutional investments, and choices related to questions(i) and (ii) above have dramatic effects on all subsequent analyses. Optimally addressing experimental design decisions can yield significant savings in both the financial and human costs, and also improve accuracy of analytical results. Therefore, a theoretical framework to enable investigators to select from a set of possible design decisions using pilot data could reap great rewards



\para{Action and Resolution} 
To this end, we have proposed and developed a formal definition of discriminability to guide data collection and processing. Discriminability is a non-parametric statistical property of a joint distribution in a hierarchical model, to differentiate between classes of objects. We prove that discriminability (which may be more aptly called reliability), provides a lower bound on predictive accuracy for any downstream inference task, even if we have never seen the covariates to predict. We then design an estimator of discriminability computed from test-restest data set, demonstrate that it is unbiased, and derive our estimator’s asymptotic distribution. 

Numerical simulations are conducted to demonstrate the basic property of our discriminability estimator in a variety of settings. Then, we apply our approach to choose amongst a set of choices one must make when designing a neuroimaging study to specifically study functional connectomics. We start by finding the maximally reliable threshold for converting correlation matrices  into graphs. Indeed, consistent with our theoretical and simulated results,
maximizing the discriminability of our datasets also maximizes performance on a suite of different downstream inference tasks. We then ask about a series of pre-processing steps: should one motion correct or not, and
should one implement global signal regression or not, etc. We determine the optimal choice for each pre-processing steps, and find the maximally discriminable pipelines amongst 64 pre-processing pipelines.

Thus, in total, our discriminability analysis is a powerful tool for making decisions about how to collect and analyze
datasets designed for discovery science. We expect this method to be useful in a wide variety of applications,
and therefore have made all the code open source and available from http://openconnecto.
me.




\section{Results}



\subsection{Theory}

\subsubsection{Definition of Discriminability}
 Discriminability measures the overall consistency and differentiability of observations. For example, if a subject is measured twice under the same conditions, two observations should be close to each other given the measure is consistent. In addition, one should be able to tell these two observations come from the same subject when compared to observations from other subjects given the measure is differentiable. We quantify this idea of consistency and differentiability through discriminability. 
 
To formalize the definition of discriminability, consider the following generative process. For each sample $i$, there exists some true physical property $\bv_i$. Unfortunately, we do not get to directly observed $\bv_i$, rather, we measure it with some device, that transforms the truth from $\bv_i$ to $\bw_i$ via $f_{\bphi}$.  The parameter $\bphi \in \bPhi$ characterizes all options in the measurement, including, for example, which scanner to use, which resolution, the number of images, sampling rate, etc.  The output of $f_{\bphi}$ is the  ``raw'' observation data $\bw_i$, but it is corrupt in various ways, including movement or intensity artifacts introduced by the measurement process.  Therefore, rather than operating directly on $\bw_i$, we intentionally ``pre-process'' the data, in an effort to remove a number of nuisance variables.  This pre-processing procedure further transforms the data from $\bw_i$ to $\bx_i$ via $g_{\bpsi}$.   The parameter $\bpsi \in \bPsi$ indexes all pre-processing options, including whether to perform motion correction, which motion correction, deconvolution, etc.  More specifically, the entire code base, including dependencies, and even the hardware the pre-processing is running on, could count as $\bpsi$. For brevity, we define $\bx_i:= g_{\bpsi} \big(f_{\bphi} (\bv_i) \big)$.

Let $i$ denote the sample's unique \emph{identity} (hereafter, referred to as the \emph{subject}) and $t$ denote the trial number.  Thus, there is a single $\bv_i$ for subject $i$, but we have $\bw_{i,t}$, which is the $t^{th}$ trial, implicitly also a function of $\bphi$, which encodes all the details of the measurement. If both $f$ and $g$ together do not introduce too much noise, then we would expect that $\bx_{i,1}$ and $\bx_{i,2}$ are \emph{closer} to one another than either are to any other subject's data, $\bx_{i',t}$.  Define $\delta$ to be a metric computing the distance between two data points, $\delta \from \mc{X} \times \mc{X} \to \Real_+$.  Formally, we expect that $\delta(\bx_{i,t},\bx_{i,t'}) \leq \delta(\bx_{i,t},\bx_{i',t''})$, for any $i,i',t,t',t''$.  
For brevity, let $\delta_{i,t,t'}:=\delta(\bx_{i,t}, \bx_{i,t'})$ and 
$\delta_{i,i',t,t''}:=\delta(\bx_{i,t}, \bx_{i',t''})$.  
This intuition leads to our definition of discriminability:
\begin{align}
D(\bpsi,\bphi) = \PP[ \delta_{i,t,t'} \leq \delta_{i,i',t,t''}]
\end{align}
When trying to find the best pre-processing routine encoded by $\bpsi$, we try to maximize the discriminability of processed data, that is 
\begin{equation} 
\begin{aligned}
& \underset{\bpsi \in \bPsi}{\text{maximize}}
& & D(\bpsi,\bphi)
\end{aligned}
\end{equation}


\subsubsection{Optimizing discriminability Optimizes Bound on Performance for Any Task}

Consider the situation that the downstream task is classification, that is in addition to $\bv_i$, there are other properties of sample $i$ of interest; we call all of them $\by_i \in \mc{Y}$.  These may include, for example, the phenotype of the subject, including personality tests, demographic information, and genetic data. The goal of experimental design, in this context, is to choose $\bphi \in \bPhi$ and $\bpsi \in \bPsi$ to make prediction of $\by_i$ based on $\bx_i$ easier. 

To quantify the performance of our choice, we introduce some assumptions.  First, assume that each $(\bv_i,\by_i)$ pair is sampled independently and identically from some distribution, $(\bv_i,\by_i) \iid F_{V,Y}$.  For simplicity, let us assume that our goal is binary classification, using $\bx_i$ as the \emph{predictor} variables, and a binary-valued $\by_i$ as the \emph{target} variable. Moreover, the loss function, $\ell$ quantifies the Bayes classification error
\[\ell( \bx_i, \by_i) =  \PP(C^{B}(\bx_i) \neq \by_i)\]
 Here, $C^{B}(\bx_i)= \underset{y_i \in \{0,1\} }{\text{argmax }} \PP(\by_i=y|\bx_i) $ . Under some assumptions, we can prove theorem 1 which asserts that Bayes classification error is bounded by an decreasing function of discriminability. 
\begin{thm}	
	There is a decreasing function $h$, such that
\[\ell( \bx_i, \by_i) \leq h(D(\bpsi,\bphi)) \]
\end{thm}

Therefore, we expect the classification performance to be better when the more discriminable processing pipeline is used. This theorem justifies
maximizing discriminability of processed data improves prediction accuracy.

\subsubsection{Estimator/Test Statistic}
In practice, exact distribution of $\bx_{i,t}$ may never known to us; hence, it is not possible to compute discriminability $D(\bpsi,\bphi)$ or $D$ in short when there is no ambiguity in processing pipelines under consideration. However, samples $x_{i,t}$ are observed, and we can approximate true discriminability using an estimator $\hat{D}$ which is a function of observed samples. For each pair of observations $x_{i,t}$ and $x_{i,t'}$ from the same subject $i$, we first define
\[ \hat{D}_{i,t,t'} = \frac{\sum\limits_{i' \neq i}^{n} \sum\limits_{t''=1}^{s} \mathbb{I}\{\delta_{i,t,t'} \leq \delta_{i,i',t,t''} \} }{(n-1)s}\]
Here, $n$ is the total number of subjects, and $s$ is the number of observations per subject. $\hat{D}_{i,t,t'}$ approximate the probability that distance between observations from other subjects and $t^{th}$ observation of subject $i$ is larger than distance between $t^{th}$ and $t'^{th}$ trial of subject $i$. Then, we define $\hat{D}$ to be the mean of $\hat{D}_{i,t,t'}$.
\[ \hat{D} := \frac{\sum\limits_{i=1}^{n} \sum\limits_{t=1}^{s}  \sum\limits_{t' \neq t}^{s} \hat{D}_{i,t,t'}}{ns(s-1)} \]
$\hat{D}$ serves as the sample approximated discriminability. The next lemma asserts the unbiasedness of $\hat{D}$ as an estimator.

\begin{lem}	
	\[ E(\hat{D}) = D\]
\end{lem}

The following lemma shows the as the number of subjects increase, $\hat{D}$ converges in probability to discriminability.
\begin{lem}	
As $n \rightarrow \infty$,
\[\hat{D} \overset{p}{\rightarrow} D \]
\end{lem}

\subsection{Simulations}

\subsubsection{Convergence of $\hat{D}$}
In Lemma 1 and 2, we assert sample discriminability $\hat{D}$ is unbiased and converges to  the true population discriminability in probability. We demonstrate this idea with simulation. The true physical property are generated from independent Gaussian distribution. That is $v_i \overset{i.i.d.}{\sim} \mathbb{G}(0,1)$. All subjects have two observations with additive noise: $x_{i,t} | v_i \sim \mathbb{G}(v_i,1)$. For each number of subjects, we generate data and compute dsicriminability 100 times. 

The figure 1 shows how $\hat{D}$ is distributed when we vary the sample size from 10 to 200. With this data generation scheme, the population discriminability can be computed from numerical integration, and is marked on the plot. We can see from the figure that sample discriminabiity $\hat{D}$ converges to $D$ as sample size increase.

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/simumnr_violin.png}
\caption{Convergence of sample Discriminability to true population Discriminability}
\label{fig:1}
\end{figure}




\subsubsection{Dhat provides a more useful bound than ICC or I2C2 for a variety of simulated settings}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/Figure1_draft.png}
\caption{Two class ICC, I2C2 and Discriminability}
\label{fig:2}
\end{figure}



\subsubsection{we can use Dhat to choose the most discriminable parameter (eg, threshold)}


\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/parameter_selection_2sub.png}
\caption{Best linear projection selected by PCA and Discriminability}
\label{fig:3}
\end{figure}




\subsection{Connectome Applications}

\subsubsection{optimal Discriminability yields optimal predictive accuracy}
\begin{itemize}
\item Introduce how fmri graph is constructed
\item Describe how we threshold correlation and what is being predicted, how we predict
\item explain the result in fig 4 that maximal discriminability yields best prediction performance 
\end{itemize}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/HCP.png}
\caption{Optimizing Discriminability yields optimal prediction accuracy for gender and age}
\label{fig:4}
\end{figure}

\begin{figure}[t!]
	\includegraphics[width=3.0in]{../Figs/pairdistance.png}
	\caption{Pairwise distance of an discriminable data set}
	\label{fig:5}
\end{figure}


\subsubsection{Best Pipeline of 64 (raw correlation graph)}
\begin{itemize}
	\item Explain the problem of finding the best pipelines
	\item Explain what four decisions are  and 4 atlases, nff vs frf, fsl vs ant, scrub vs no scr, gsr vs no gsr. 
	\item Claim we find the best pipeline with maximum mean (without a hypothesis tesing)
\end{itemize}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/64_pipelines_size.png}
\caption{Discriminability of raw fmri graphs from 12 data sets processed 64 ways ordered by putting better decisions in front}
\label{fig:6}
\end{figure}


\subsubsection{best pipeline = product of marginals}
\begin{itemize}
	\item Explain we focus on individual decision for statistical significance
	\item Explain how we perform the multifactor analysis of variance test
	\item we find nff better than frf, fsl better than ant, scrub ? no scr, gsr better than no gsr, and atlas is being significant, best pipeline = product of marginals
\end{itemize}

\begin{figure}[t!]
\includegraphics[width=3.0in]{../Figs/Differ_violin_mean.png}
\caption{Paired difference in Discriminability of each decisions}
\label{fig:7}
\end{figure}

\subsubsection{which atlas/resolution}
\begin{itemize}
	\item Background info about 4 atlases
	\item claim cc200 better than hox  better than aal better than des
\end{itemize}

\subsubsection{rank graphs}

\begin{itemize}
	\item Explain how rank graphs are constructed, the motivation to robust estimate graphs
	\item Explain it offers large improvement over raw fmri graphs when there is no gsr, small when there is gsr.s
\end{itemize}
\begin{figure}[t!]
	\includegraphics[width=3.0in]{../Figs/64_pipelines_size_rank.png}
	\caption{Discriminability of rank fmri graphs from 12 data sets processed 64}
	\label{fig:8}
\end{figure}


\begin{figure}[t!]
	\includegraphics[width=3.0in]{../Figs/64_pipelines_differ.png}
	\caption{Difference in Discriminability of rank vs raw fmri graphs from 12 data sets processed 64}
	\label{fig:9}
\end{figure}




\subsubsection{DTI vs. fMRI}










\section{Discussion}

\para{Summary}

\para{Related Work}
Our discriminability statistics is not the first attempt to quantify information of test-retest data set. Previous works include but not limit to: analysis of variance (ANOVA), intraclass correlation coefficient (ICC), image intraclass correlation coefficient (I2C2) and distance components (DISCO). The ANOVA and ICC approaches only operate on scalar data set. I2C2 is a generalization of ICC into high dimension space, however it is designed for additive Gaussian noise and assumes Euclidean distance. DISCO is a statistics designed to test whether multi-modal distribution are the same or not. It is less robust and intuitive compared to $\hat{D}$. Also, the mean of DISCO varies with the number of subject and dimension of observation which makes it not suitable to compare across data set.


\para{Next Steps}


% \input{intro}
% \input{simulations}
% \input{flow}
% \input{setting}
% \input{logic}
% \input{main}
% \input{setup}
% \input{gRAICAR}



\appendix






\newpage
\small{
\bibliography{biblio}
\bibliographystyle{IEEEtran}
}


\end{document}
